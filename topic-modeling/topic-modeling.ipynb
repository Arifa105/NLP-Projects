{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7609ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I love programming in Python',\n",
       " 'Python and Java are popular programming languages',\n",
       " 'I enjoy learning new programming languages',\n",
       " 'Machine learning is fascinating',\n",
       " 'Deep learning and neural networks are part of machine learning',\n",
       " 'Natural language processing (NLP) is a branch of artificial intelligence',\n",
       " 'NLP techniques include tokenization, stemming, and lemmatization',\n",
       " 'Supervised learning algorithms include regression and classification',\n",
       " 'Unsupervised learning includes clustering and association',\n",
       " 'Reinforcement learning involves agents learning from their environment']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example documents\n",
    "documents = [\n",
    "    \"I love programming in Python\",\n",
    "    \"Python and Java are popular programming languages\",\n",
    "    \"I enjoy learning new programming languages\",\n",
    "    \"Machine learning is fascinating\",\n",
    "    \"Deep learning and neural networks are part of machine learning\",\n",
    "    \"Natural language processing (NLP) is a branch of artificial intelligence\",\n",
    "    \"NLP techniques include tokenization, stemming, and lemmatization\",\n",
    "    \"Supervised learning algorithms include regression and classification\",\n",
    "    \"Unsupervised learning includes clustering and association\",\n",
    "    \"Reinforcement learning involves agents learning from their environment\"\n",
    "]\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db38a83f",
   "metadata": {},
   "source": [
    "# Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86490c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Steps\n",
    "# Lowercasing: Convert all characters to lowercase.\n",
    "# Removing Punctuation: Remove punctuation marks.\n",
    "# Removing Stopwords: Remove common stopwords like \"and\", \"the\", etc.\n",
    "# Tokenization: Split text into individual words.\n",
    "# Stemming/Lemmatization: Reduce words to their root form (optional).\n",
    "\n",
    "#==============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2970f478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love', 'watching', 'action', 'movies']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#regular express re help to clean teext\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]\n",
    "      # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "dummy_text = \"I love watching action # &%!@ Movies\"\n",
    "preprocess_text(dummy_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7dc66b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love programming python',\n",
       " 'python java popular programming languages',\n",
       " 'enjoy learning new programming languages',\n",
       " 'machine learning fascinating',\n",
       " 'deep learning neural networks machine learning',\n",
       " 'natural language processing nlp branch artificial intelligence',\n",
       " 'nlp techniques include tokenization stemming lemmatization',\n",
       " 'supervised learning algorithms include regression classification',\n",
       " 'unsupervised learning includes clustering association',\n",
       " 'reinforcement learning involves agents learning environment']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#regular express re help to clean teext\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in ENGLISH_STOP_WORDS]\n",
    "      # Join tokens back to string\n",
    "    return ' '.join(tokens)\n",
    "# Preprocess the documents\n",
    "preprocessed_documents = [preprocess_text(doc) for doc in documents]\n",
    "preprocessed_documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7f46d2",
   "metadata": {},
   "source": [
    "# Countvectorizer (Text to numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b2fb14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if simple data so we using countVectorizer, but you can used TF/IDF for large data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Convert the documents to a term-document matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b06a4a14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<10x38 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 50 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38980d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0,\n",
       "         1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "        [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to visulized the vectorization\n",
    "# optional code \n",
    "# Convert the sparse matrix to a dense format\n",
    "dense_matrix = X.todense()\n",
    "dense_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad4db6c",
   "metadata": {},
   "source": [
    "# Apply LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4906458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=2, random_state=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "# Fit the LDA model\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=0)\n",
    "lda.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e27941",
   "metadata": {},
   "source": [
    "# Display Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b36d0538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['agents', 'algorithms', 'artificial', 'association', 'branch',\n",
       "       'classification', 'clustering', 'deep', 'enjoy', 'environment',\n",
       "       'fascinating', 'include', 'includes', 'intelligence', 'involves',\n",
       "       'java', 'language', 'languages', 'learning', 'lemmatization',\n",
       "       'love', 'machine', 'natural', 'networks', 'neural', 'new', 'nlp',\n",
       "       'popular', 'processing', 'programming', 'python', 'regression',\n",
       "       'reinforcement', 'stemming', 'supervised', 'techniques',\n",
       "       'tokenization', 'unsupervised'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdc8b223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.49322283, 1.49037146, 0.50159757, 1.49157   , 0.50159757,\n",
       "        1.49037146, 1.49157   , 1.49334248, 1.49200711, 1.49322283,\n",
       "        1.48643702, 1.44245445, 1.49157   , 0.50159757, 1.49322283,\n",
       "        1.4918633 , 0.50159757, 2.49170597, 8.49139308, 0.50197213,\n",
       "        1.48619725, 2.48966229, 0.50159757, 1.49334248, 1.49334248,\n",
       "        1.49200711, 0.50183317, 1.4918633 , 0.50159757, 3.48971323,\n",
       "        2.48875502, 1.49037146, 1.49322283, 0.50197213, 1.49037146,\n",
       "        0.50197213, 0.50197213, 1.49157   ],\n",
       "       [0.50677717, 0.50962854, 1.49840243, 0.50843   , 1.49840243,\n",
       "        0.50962854, 0.50843   , 0.50665752, 0.50799289, 0.50677717,\n",
       "        0.51356298, 1.55754555, 0.50843   , 1.49840243, 0.50677717,\n",
       "        0.5081367 , 1.49840243, 0.50829403, 0.50860692, 1.49802787,\n",
       "        0.51380275, 0.51033771, 1.49840243, 0.50665752, 0.50665752,\n",
       "        0.50799289, 2.49816683, 0.5081367 , 1.49840243, 0.51028677,\n",
       "        0.51124498, 0.50962854, 0.50677717, 1.49802787, 0.50962854,\n",
       "        1.49802787, 1.49802787, 0.50843   ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa88f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['learning', 'programming', 'languages', 'machine', 'python', 'neural', 'deep', 'networks', 'environment', 'involves']\n",
      "Topic 1:\n",
      "['nlp', 'include', 'processing', 'natural', 'branch', 'intelligence', 'artificial', 'language', 'stemming', 'techniques']\n"
     ]
    }
   ],
   "source": [
    "#extract index, topic, with the help of enumartor call lda_componets\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {idx}:\")\n",
    "    print([vectorizer.get_feature_names_out()[i] for i in topic.argsort()[:-10 - 1:-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68146fc",
   "metadata": {},
   "source": [
    "# Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fa1565d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>learning</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>programming</td>\n",
       "      <td>include</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>languages</td>\n",
       "      <td>processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>machine</td>\n",
       "      <td>natural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>python</td>\n",
       "      <td>branch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>neural</td>\n",
       "      <td>intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deep</td>\n",
       "      <td>artificial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>networks</td>\n",
       "      <td>language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>environment</td>\n",
       "      <td>stemming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>involves</td>\n",
       "      <td>techniques</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Topic 1       Topic 2\n",
       "0     learning           nlp\n",
       "1  programming       include\n",
       "2    languages    processing\n",
       "3      machine       natural\n",
       "4       python        branch\n",
       "5       neural  intelligence\n",
       "6         deep    artificial\n",
       "7     networks      language\n",
       "8  environment      stemming\n",
       "9     involves    techniques"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    topic_dict = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        topic_dict[f\"Topic {topic_idx+1}\"] = [feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]\n",
    "    return topic_dict\n",
    "\n",
    "no_top_words = 10\n",
    "topics = display_topics(lda, vectorizer.get_feature_names_out(), no_top_words)\n",
    "\n",
    "# Convert the topics dictionary to a DataFrame for better visualization\n",
    "topics_df = pd.DataFrame(topics)\n",
    "\n",
    "\n",
    "topics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509e160f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132edee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531e6dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
